{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch torchvision transformers opencv-python pandas ultralytics moviepy ollama\n",
    "# Download ollama from website: \n",
    "# Run in Console: ollama pull llava:13b\n",
    "# Run in Console: ollama run llava\n",
    "# Run this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import pandas as pd\n",
    "from moviepy.editor import VideoFileClip\n",
    "from PIL import Image\n",
    "import io\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to extract frames from video and return them as bytes\n",
    "def extract_frames(video_path, frame_rate=1):\n",
    "    clip = VideoFileClip(video_path)\n",
    "    fps = clip.fps\n",
    "    frame_list = []\n",
    "    timestamps = []\n",
    "\n",
    "    for i, frame in enumerate(clip.iter_frames()):\n",
    "        if i % int(fps / frame_rate) == 0:\n",
    "            # Convert frame (numpy array) to PIL Image\n",
    "            image = Image.fromarray(frame)\n",
    "            # Save the image to a bytes buffer\n",
    "            buffer = io.BytesIO()\n",
    "            image.save(buffer, format=\"JPEG\")\n",
    "            buffer.seek(0)\n",
    "            # Append the bytes buffer to the list\n",
    "            frame_list.append(buffer)\n",
    "            timestamps.append(i / fps)\n",
    "\n",
    "    return frame_list, timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects(input):\n",
    "    message_list = []\n",
    "\n",
    "    # Use tqdm for progress bar\n",
    "    for i in tqdm(input, desc=\"Detecting Objects in Images\"):\n",
    "        res = ollama.chat(\n",
    "            model='llava',\n",
    "            messages=[\n",
    "                {\n",
    "                    'role': 'user',\n",
    "                    'content': 'Describe all objects seen in this image',\n",
    "                    'images': [i]\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        message_list.append(res['message']['content'])\n",
    "\n",
    "    return message_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def theme_detection(input):\n",
    "    message_list = []\n",
    "    \n",
    "    # Use tqdm for progress bar\n",
    "    for i in tqdm(input, desc=\"Processing Images\"):\n",
    "        res = ollama.chat(\n",
    "            model='llava',\n",
    "            messages=[\n",
    "                {\n",
    "                    'role': 'user',\n",
    "                    'content': 'Describe the theme of this image',\n",
    "                    'images': [i]\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        message_list.append(res['message']['content'])\n",
    "\n",
    "    return message_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to process video and return a DataFrame\n",
    "def analyze_video(video_path):\n",
    "    print(f\"Extracting frames from video ({video_path})...\")\n",
    "    # Change frames to fit video 0.5 means half of the frames, 1 is all the frames\n",
    "    frames, timestamps = extract_frames(video_path, frame_rate=0.02)\n",
    "\n",
    "    print(\"Running object detection...\")\n",
    "    object_data = detect_objects(frames)\n",
    "\n",
    "    # print(\"Running theme detection...\")\n",
    "    # theme_data = theme_detection(frames)\n",
    "\n",
    "    # Create a DataFrame with results\n",
    "    data = {\n",
    "        \"Timestamp\": timestamps,\n",
    "        \"Detected Objects\": object_data\n",
    "        #\"Theme Embeddings\": theme_data\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames from video (Test.mp4)...\n",
      "Running object detection...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting Objects in Images: 100%|██████████| 11/11 [31:34<00:00, 172.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Timestamp                                   Detected Objects\n",
      "0     0.000000   The image is quite small and low-resolution, ...\n",
      "1    49.983267   The image shows a person with their arm raise...\n",
      "2    99.966533   In the image, there is a person sitting at a ...\n",
      "3   149.949800   The image shows a person using a smartwatch w...\n",
      "4   199.933067   In the image, there is a person holding a sma...\n",
      "5   249.916333   The image shows a person seated and looking d...\n",
      "6   299.899600   In the image, there is a person giving a thum...\n",
      "7   349.882867   The image is a screenshot from a video, likel...\n",
      "8   399.866133   The image appears to be a screenshot from a v...\n",
      "9   449.849400   The image shows a person sitting at a desk wi...\n",
      "10  499.832667   In the image, we see a man standing indoors. ...\n"
     ]
    }
   ],
   "source": [
    "# Upload and analyze your .mp4 video file\n",
    "video_path = \"Test.mp4\"\n",
    "df_results = analyze_video(video_path)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv('VideoResults2.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
