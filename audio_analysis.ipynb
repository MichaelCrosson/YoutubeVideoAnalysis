{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import torchaudio\n",
    "from pydub import AudioSegment\n",
    "from collections import Counter\n",
    "from speechbrain.pretrained import EncoderClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install speechbrain\n",
    "!pip install git+https://github.com/speechbrain/speechbrain.git@develop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PATH\"] += os.pathsep + \"/opt/homebrew/bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert .mp4 files to .wav\n",
    "videos_folder = \"Videos\"\n",
    "\n",
    "for file_name in os.listdir(videos_folder):\n",
    "    if file_name.lower().endswith(\".mp4\")\n",
    "        video_path = os.path.join(videos_folder, file_name)\n",
    "        wav_path = os.path.splitext(video_path)[0] + \".wav\"\n",
    "        \n",
    "        try:\n",
    "            audio = AudioSegment.from_file(video_path, format=\"mp4\")\n",
    "            audio.export(wav_path, format=\"wav\")\n",
    "            print(f\"Converted {file_name} to {wav_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error converting {file_name}: {e}\")\n",
    "\n",
    "print(\"All videos have been processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from speechbrain.inference.interfaces import foreign_class\n",
    "classifier = foreign_class(source=\"speechbrain/emotion-recognition-wav2vec2-IEMOCAP\", pymodule_file=\"custom_interface.py\", classname=\"CustomEncoderWav2vec2Classifier\")\n",
    "out_prob, score, index, text_lab = classifier.classify_file(\"speechbrain/emotion-recognition-wav2vec2-IEMOCAP/anger.wav\")\n",
    "print(text_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Wav2Vec\n",
    "classifier = EncoderClassifier.from_hparams(\n",
    "    source=\"speechbrain/emotion-recognition-wav2vec2-IEMOCAP\",\n",
    "    savedir=\"pretrained_models/emotion_recognition\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_folder = \"Videos\"\n",
    "output_csv_file = \"chunk_emotions.csv\"\n",
    "\n",
    "all_emotions = {}\n",
    "\n",
    "for file_name in os.listdir(audio_folder):\n",
    "    if file_name.lower().endswith(\".wav\"):\n",
    "        file_path = os.path.join(audio_folder, file_name)\n",
    "        signal, fs = torchaudio.load(file_path)\n",
    "\n",
    "        if signal.shape[0] > 1:\n",
    "            signal = signal.mean(dim=0, keepdim=True)\n",
    "\n",
    "        if fs != 16000:\n",
    "            resampler = torchaudio.transforms.Resample(orig_freq=fs, new_freq=16000)\n",
    "            signal = resampler(signal)\n",
    "            fs = 16000\n",
    "\n",
    "        num_samples = signal.shape[1]\n",
    "        num_chunks = 25\n",
    "        chunk_length = (num_samples + num_chunks - 1) // num_chunks\n",
    "        chunk_emotions = []\n",
    "\n",
    "        for i in range(num_chunks):\n",
    "            start = i * chunk_length\n",
    "            end = min((i + 1) * chunk_length, num_samples)\n",
    "            chunk = signal[:, start:end]\n",
    "\n",
    "            features = classifier.mods.wav2vec2(chunk)\n",
    "            pooled_features = classifier.mods.avg_pool(features)\n",
    "            logits = classifier.mods.output_mlp(pooled_features)\n",
    "            score, index = logits.max(dim=-1)\n",
    "            predicted_emotion = classifier.hparams.label_encoder.decode_torch(index)\n",
    "\n",
    "            chunk_emotions.append(predicted_emotion[0][0])\n",
    "\n",
    "        video_name = os.path.splitext(file_name)[0]\n",
    "        all_emotions[video_name] = chunk_emotions\n",
    "\n",
    "with open(output_csv_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    header = [\"Chunk\"] + list(all_emotions.keys())\n",
    "    writer.writerow(header)\n",
    "    \n",
    "    for i in range(num_chunks):\n",
    "        row = [i + 1] \n",
    "        for video_name in all_emotions.keys():\n",
    "            row.append(all_emotions[video_name][i])\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"Predicted emotions for all chunks and all files saved to: {output_csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for video_name, emotions in all_emotions.items():\n",
    "    total_chunks = len(emotions) \n",
    "    emotion_counts = {\n",
    "        \"neutral\": emotions.count(\"neu\"),\n",
    "        \"happy\": emotions.count(\"hap\"),\n",
    "        \"sad\": emotions.count(\"sad\"),\n",
    "        \"angry\": emotions.count(\"ang\")\n",
    "    }\n",
    "\n",
    "    emotion_percentages = {\n",
    "        \"neutral_percent\": (emotion_counts[\"neutral\"] / total_chunks),\n",
    "        \"happy_percent\": (emotion_counts[\"happy\"] / total_chunks),\n",
    "        \"sad_percent\": (emotion_counts[\"sad\"] / total_chunks),\n",
    "        \"angry_percent\": (emotion_counts[\"angry\"] / total_chunks)\n",
    "    }\n",
    "\n",
    "    results.append({\"video_name\": video_name, **emotion_percentages})\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "output_csv_file = \"video_emotion_percentages.csv\"\n",
    "df.to_csv(output_csv_file, index=False)\n",
    "\n",
    "print(f\"Emotion percentages have been saved to {output_csv_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
