{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e3ff17b-6062-4f2c-9545-73b559c087fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall gensim\n",
    "# !pip uninstall scipy\n",
    "# !pip install scipy==1.10.1\n",
    "# !pip install gensim==4.3.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbf186b1-8dd9-489f-b3d6-4c52e416d6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "# from gensim import corpora\n",
    "# from gensim.models import LdaModel\n",
    "# from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7a48b73-eba4-48f7-9038-cf957514690b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['channel_name', 'video_id', 'video_title', 'published_datetime',\n",
       "       'duration', 'view_count', 'like_count', 'dislike_count',\n",
       "       'comment_count', 'description', 'thumbnail_url', 'transcript'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_details_file = \"Video_Transcripts.csv\"\n",
    "video_transcripts = pd.read_csv(video_details_file)\n",
    "video_transcripts.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e4532c3-d27c-48ca-8ef1-4c5512cb5728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['channel_name', 'class', 'video_id', 'video_title',\n",
       "       'published_datetime', 'duration', 'view_count', 'like_count',\n",
       "       'dislike_count', 'comment_count', 'description', 'thumbnail_url',\n",
       "       'transcript'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_df = pd.read_csv('videos_selected.csv', encoding='ISO-8859-1')\n",
    "class_df.columns\n",
    "\n",
    "channel_class_map = class_df.set_index('channel_name')['youtube_tier'].to_dict()\n",
    "\n",
    "video_transcripts['class'] = video_transcripts['channel_name'].map(channel_class_map)\n",
    "\n",
    "columns = video_transcripts.columns.tolist()\n",
    "channel_index = columns.index('channel_name')\n",
    "columns.remove('class')  # Remove 'class' from current position if it exists\n",
    "columns.insert(channel_index + 1, 'class')  # Insert 'class' after 'channel_name'\n",
    "\n",
    "video_transcripts = video_transcripts[columns]\n",
    "\n",
    "video_transcripts.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eebfe33b-3e80-4231-b5e3-7e94d0c1c07e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_name</th>\n",
       "      <th>class</th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_title</th>\n",
       "      <th>transcript</th>\n",
       "      <th>hook</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Mrwhosetheboss</td>\n",
       "      <td>Diamond</td>\n",
       "      <td>neIYdLysqlk</td>\n",
       "      <td>I tested the Craziest Xiaomi Gadgets!</td>\n",
       "      <td>you probably know xiaomi for their suspiciousl...</td>\n",
       "      <td>you probably know xiaomi for their suspiciousl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Mrwhosetheboss</td>\n",
       "      <td>Diamond</td>\n",
       "      <td>YX8ks42Azn8</td>\n",
       "      <td>The TRIPLE FOLDING phone has a Problem.</td>\n",
       "      <td>this right here is the Huawei mate XT I spent ...</td>\n",
       "      <td>this right here is the Huawei mate XT I spent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Mrwhosetheboss</td>\n",
       "      <td>Diamond</td>\n",
       "      <td>4RcThoRG46c</td>\n",
       "      <td>I tested every Celebrity Tech product!</td>\n",
       "      <td>in front of me right now are VTech products ma...</td>\n",
       "      <td>in front of me right now are VTech products ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      channel_name    class     video_id  \\\n",
       "0  @Mrwhosetheboss  Diamond  neIYdLysqlk   \n",
       "1  @Mrwhosetheboss  Diamond  YX8ks42Azn8   \n",
       "2  @Mrwhosetheboss  Diamond  4RcThoRG46c   \n",
       "\n",
       "                               video_title  \\\n",
       "0    I tested the Craziest Xiaomi Gadgets!   \n",
       "1  The TRIPLE FOLDING phone has a Problem.   \n",
       "2   I tested every Celebrity Tech product!   \n",
       "\n",
       "                                          transcript  \\\n",
       "0  you probably know xiaomi for their suspiciousl...   \n",
       "1  this right here is the Huawei mate XT I spent ...   \n",
       "2  in front of me right now are VTech products ma...   \n",
       "\n",
       "                                                hook  \n",
       "0  you probably know xiaomi for their suspiciousl...  \n",
       "1  this right here is the Huawei mate XT I spent ...  \n",
       "2  in front of me right now are VTech products ma...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_transcripts = video_transcripts[['channel_name', 'class','video_id', 'video_title', 'transcript']].copy()\n",
    "\n",
    "video_transcripts['hook'] = video_transcripts['transcript'].apply(\n",
    "    lambda x: ' '.join(x.split()[:75]) if isinstance(x, str) else ''\n",
    ")\n",
    "\n",
    "video_transcripts.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce6c1544-2a08-4f85-9b61-cc604c398f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment analysis complete. Results saved to 'Video_Transcripts_With_Sentiment.csv'.\n"
     ]
    }
   ],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Perform sentiment analysis on a given text\n",
    "def analyze_sentiment(text):\n",
    "    if isinstance(text, str) and text.strip():\n",
    "        scores = sia.polarity_scores(text)\n",
    "        return scores['compound']  # Use compound score as overall sentiment\n",
    "    else:\n",
    "        return None  # Handle missing or non-string text\n",
    "\n",
    "# Perform sentiment analysis for title, transcript, and hook\n",
    "video_transcripts['title_sentiment'] = video_transcripts['video_title'].apply(analyze_sentiment)\n",
    "video_transcripts['transcript_sentiment'] = video_transcripts['transcript'].apply(analyze_sentiment)\n",
    "video_transcripts['hook_sentiment'] = video_transcripts['hook'].apply(analyze_sentiment)\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "video_transcripts.to_csv(\"Video_Transcripts_With_Sentiment.csv\", index=False)\n",
    "\n",
    "print(\"Sentiment analysis complete. Results saved to 'Video_Transcripts_With_Sentiment.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f678e04b-4298-491e-b4ae-b6402cc816b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_name</th>\n",
       "      <th>class</th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_title</th>\n",
       "      <th>transcript</th>\n",
       "      <th>hook</th>\n",
       "      <th>title_sentiment</th>\n",
       "      <th>transcript_sentiment</th>\n",
       "      <th>hook_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Mrwhosetheboss</td>\n",
       "      <td>Diamond</td>\n",
       "      <td>neIYdLysqlk</td>\n",
       "      <td>I tested the Craziest Xiaomi Gadgets!</td>\n",
       "      <td>you probably know xiaomi for their suspiciousl...</td>\n",
       "      <td>you probably know xiaomi for their suspiciousl...</td>\n",
       "      <td>-0.1260</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Mrwhosetheboss</td>\n",
       "      <td>Diamond</td>\n",
       "      <td>YX8ks42Azn8</td>\n",
       "      <td>The TRIPLE FOLDING phone has a Problem.</td>\n",
       "      <td>this right here is the Huawei mate XT I spent ...</td>\n",
       "      <td>this right here is the Huawei mate XT I spent ...</td>\n",
       "      <td>-0.4019</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>-0.8691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Mrwhosetheboss</td>\n",
       "      <td>Diamond</td>\n",
       "      <td>4RcThoRG46c</td>\n",
       "      <td>I tested every Celebrity Tech product!</td>\n",
       "      <td>in front of me right now are VTech products ma...</td>\n",
       "      <td>in front of me right now are VTech products ma...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Mrwhosetheboss</td>\n",
       "      <td>Diamond</td>\n",
       "      <td>vSIbvJB4WdI</td>\n",
       "      <td>iPhone 16 Pro Max vs Samsung S24 Ultra Camera ...</td>\n",
       "      <td>this is the iPhone 16 Pro Max this is the Sams...</td>\n",
       "      <td>this is the iPhone 16 Pro Max this is the Sams...</td>\n",
       "      <td>-0.4389</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.7184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Mrwhosetheboss</td>\n",
       "      <td>Diamond</td>\n",
       "      <td>cRPBp2tRxFY</td>\n",
       "      <td>iPhone 16 / 16 Pro Unboxing - Testing every ne...</td>\n",
       "      <td>this is the iPhone 16 the iPhone 16 plus the 1...</td>\n",
       "      <td>this is the iPhone 16 the iPhone 16 plus the 1...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.6124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      channel_name    class     video_id  \\\n",
       "0  @Mrwhosetheboss  Diamond  neIYdLysqlk   \n",
       "1  @Mrwhosetheboss  Diamond  YX8ks42Azn8   \n",
       "2  @Mrwhosetheboss  Diamond  4RcThoRG46c   \n",
       "3  @Mrwhosetheboss  Diamond  vSIbvJB4WdI   \n",
       "4  @Mrwhosetheboss  Diamond  cRPBp2tRxFY   \n",
       "\n",
       "                                         video_title  \\\n",
       "0              I tested the Craziest Xiaomi Gadgets!   \n",
       "1            The TRIPLE FOLDING phone has a Problem.   \n",
       "2             I tested every Celebrity Tech product!   \n",
       "3  iPhone 16 Pro Max vs Samsung S24 Ultra Camera ...   \n",
       "4  iPhone 16 / 16 Pro Unboxing - Testing every ne...   \n",
       "\n",
       "                                          transcript  \\\n",
       "0  you probably know xiaomi for their suspiciousl...   \n",
       "1  this right here is the Huawei mate XT I spent ...   \n",
       "2  in front of me right now are VTech products ma...   \n",
       "3  this is the iPhone 16 Pro Max this is the Sams...   \n",
       "4  this is the iPhone 16 the iPhone 16 plus the 1...   \n",
       "\n",
       "                                                hook  title_sentiment  \\\n",
       "0  you probably know xiaomi for their suspiciousl...          -0.1260   \n",
       "1  this right here is the Huawei mate XT I spent ...          -0.4019   \n",
       "2  in front of me right now are VTech products ma...           0.0000   \n",
       "3  this is the iPhone 16 Pro Max this is the Sams...          -0.4389   \n",
       "4  this is the iPhone 16 the iPhone 16 plus the 1...           0.0000   \n",
       "\n",
       "   transcript_sentiment  hook_sentiment  \n",
       "0                1.0000          0.9598  \n",
       "1                0.9999         -0.8691  \n",
       "2                1.0000          0.9552  \n",
       "3                0.9999          0.7184  \n",
       "4                0.9999          0.6124  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_transcripts = pd.read_csv(\"Video_Transcripts_With_Sentiment.csv\")\n",
    "video_transcripts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8c16b73-58c3-4e32-b4bf-49c94a30b5a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['channel_name', 'class', 'video_id', 'video_title', 'transcript',\n",
       "       'hook', 'title_sentiment', 'transcript_sentiment', 'hook_sentiment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_transcripts.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4235db1f-275a-4313-b36d-6d8e87f59f4b",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3474aaa6-525c-4cac-9c71-bc46a13f3914",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts = video_transcripts['transcript']\n",
    "\n",
    "# Step 2: TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words='english',  # Remove common English words\n",
    "    max_features=5000,    # Limit to 5000 most important terms\n",
    "    ngram_range=(1, 2)    # Consider unigrams and bigrams\n",
    ")\n",
    "tfidf_matrix = vectorizer.fit_transform(transcripts)\n",
    "\n",
    "# Step 3: Apply NMF for Topic Modeling\n",
    "n_topics = 5  # Specify the number of topics to extract\n",
    "nmf_model = NMF(n_components=n_topics, random_state=42)\n",
    "nmf_matrix = nmf_model.fit_transform(tfidf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcda6b9-3e5b-4235-95a5-7a35c59237a6",
   "metadata": {},
   "source": [
    "## NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "496c553b-f821-4570-92ac-52742a0834cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: like, just, phone, m4, mac, actually, oh, thing, screen, really\n",
      "Topic 2: tv, box, 4k, dolby, google, got, ve got, remote, hdr, streaming\n",
      "Topic 3: watch, apple watch, apple, series, series 10, watches, like, watch ultra, watch series, 10\n",
      "Topic 4: airpods, ear, sound, airpods pro, like, noise, pro, ear design, earbuds, cancellation\n",
      "Topic 5: iphone, camera, apple, iphone 16, 16, like, phones, phone, new, pro\n",
      "Topic modeling complete. Results saved to 'Video_Transcripts_With_Topics.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Extract Topic Keywords\n",
    "def display_topics(model, feature_names, n_top_words):\n",
    "    topics = {}\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_words = [feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
    "        topics[topic_idx] = top_words\n",
    "        print(f\"Topic {topic_idx + 1}: {', '.join(top_words)}\")\n",
    "    return topics\n",
    "\n",
    "n_top_words = 10\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "topics = display_topics(nmf_model, feature_names, n_top_words)\n",
    "\n",
    "# Step 5: Assign Topics to Transcripts\n",
    "video_transcripts['topic'] = nmf_matrix.argmax(axis=1)\n",
    "\n",
    "# Save the updated DataFrame to a new file\n",
    "video_transcripts.to_csv(\"Video_Transcripts_With_Topics.csv\", index=False)\n",
    "\n",
    "print(\"Topic modeling complete. Results saved to 'Video_Transcripts_With_Topics.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba11f241-b322-43a9-861e-113c40a91d48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#video_transcripts['topic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58523ea4-9eb8-470b-89f4-957db3fa54ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic 1: Smartphones and Apple Products\n",
    "# Topic 2: TVs and Home Entertainment\n",
    "# Topic 3: Wearables (Apple Watch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42ce64a6-c88b-4631-8d1e-ac0b938b7c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic 1: General Impressions and Screens\n",
    "# Topic 2: TVs and Streaming Devices\n",
    "# Topic 3: Apple Watch and Wearables\n",
    "# Topic 4: AirPods and Audio Accessories\n",
    "# Topic 5: iPhone and Cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "530d1f94-e482-4419-a8cc-7322f5320f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic  class  \n",
       "0      Diamond    10\n",
       "       Gold        8\n",
       "       Silver      1\n",
       "1      Silver      5\n",
       "2      Gold        4\n",
       "       Silver      2\n",
       "3      Silver      4\n",
       "       Diamond     1\n",
       "4      Diamond     4\n",
       "       Gold        3\n",
       "       Silver      3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_transcripts.groupby('topic')['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a21afe-be59-4d29-8c09-ce64a33fc5e0",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbcb8447-5677-4135-a62f-b985df525a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = CountVectorizer(stop_words='english', max_features=5000)\n",
    "# doc_term_matrix = vectorizer.fit_transform(transcripts).toarray()\n",
    "\n",
    "# # Create a dictionary and corpus\n",
    "# dictionary = corpora.Dictionary([vectorizer.get_feature_names_out()])\n",
    "# corpus = [dictionary.doc2bow(doc) for doc in doc_term_matrix]\n",
    "\n",
    "# # Train LDA model\n",
    "# lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=5, random_state=42)\n",
    "\n",
    "# # Display topics\n",
    "# topics = lda_model.print_topics(num_words=10)\n",
    "# for topic in topics:\n",
    "#     print(topic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2346e702-8f24-4a5b-ad19-2e6d0a461bc9",
   "metadata": {},
   "source": [
    "# BERTopic - more nuanced than NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3897b6b0-0649-4029-8db2-2374320bb6f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from bertopic import BERTopic\n",
    "\n",
    "# # Train BERTopic model\n",
    "# topic_model = BERTopic()\n",
    "# topics, probs = topic_model.fit_transform(transcripts)\n",
    "\n",
    "# # Assign topics to the DataFrame\n",
    "# video_transcripts['topic'] = topics\n",
    "\n",
    "# # Visualize topics without filtering manually\n",
    "# topic_model.visualize_topics()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397ddfe7-211a-4f65-8e4a-792acd99ea38",
   "metadata": {},
   "source": [
    "# LSA - ideal for longer documents so meh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8aa2a8ed-04a3-4f12-812c-55aee6efdd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: phones, really, new, phone, camera, pro, iphone, apple, just, like\n",
      "Topic 1: streaming, hdr, remote, macbook, google, got, box, dolby, 4k, tv\n",
      "Topic 2: little, oneplus, open, earbuds, cancellation, like, noise, sound, ear, airpods\n",
      "Topic 3: ipad, like, black, m4, mac, 10, watches, apple, series, watch\n",
      "Topic 4: huawei, thing, folding, base, gpu, thunderbolt, mini, like, m4, mac\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Vectorize transcripts with TF-IDF\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "tfidf_matrix = vectorizer.fit_transform(video_transcripts['transcript'].fillna(''))\n",
    "\n",
    "# Apply Truncated SVD\n",
    "n_topics = 5\n",
    "lsa_model = TruncatedSVD(n_components=n_topics, random_state=42)\n",
    "lsa_matrix = lsa_model.fit_transform(tfidf_matrix)\n",
    "\n",
    "# Print topics\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "for i, comp in enumerate(lsa_model.components_):\n",
    "    terms_in_topic = [terms[idx] for idx in comp.argsort()[-10:]]\n",
    "    print(f\"Topic {i}: {', '.join(terms_in_topic)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5473c63b-28d2-4d64-9cff-8accb2ea0db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic  class  \n",
       "0      Diamond    10\n",
       "       Gold        8\n",
       "       Silver      1\n",
       "1      Silver      5\n",
       "2      Gold        4\n",
       "       Silver      2\n",
       "3      Silver      4\n",
       "       Diamond     1\n",
       "4      Diamond     4\n",
       "       Gold        3\n",
       "       Silver      3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_transcripts.groupby('topic')['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a358c465-8b3b-4b3a-82a3-42c8fa121fda",
   "metadata": {},
   "source": [
    "# K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fe03c19-82af-4a82-9b47-c727f2f34d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: thunderbolt, apple, just, ipad, pro, mini, macbook, mac, m4, like\n",
      "Cluster 1: going, ear, camera, watch, airpods, pro, iphone, just, apple, like\n",
      "Cluster 2: iphone, year, huawei, folding, camera, screen, just, phones, phone, like\n",
      "Cluster 3: streaming, hdr, drive, remote, got, google, dolby, box, 4k, tv\n",
      "Cluster 4: nova, magic, red, book, yoga, keyboard, hp, elite, processor, laptop\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Vectorize transcripts\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "tfidf_matrix = vectorizer.fit_transform(video_transcripts['transcript'].fillna(''))\n",
    "\n",
    "# Apply K-Means clustering\n",
    "n_clusters = 5\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "video_transcripts['topic'] = kmeans.fit_predict(tfidf_matrix)\n",
    "\n",
    "# Print top terms per cluster\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "for i in range(n_clusters):\n",
    "    cluster_terms = tfidf_matrix[kmeans.labels_ == i].mean(axis=0).A1\n",
    "    top_terms = [terms[idx] for idx in cluster_terms.argsort()[-10:]]\n",
    "    print(f\"Cluster {i}: {', '.join(top_terms)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88f1bf62-a617-4acd-8f20-b79f33c030e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>class</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Gold</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Diamond</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Silver</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Diamond</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Silver</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>Gold</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>Diamond</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>Gold</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>Silver</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>Silver</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>Gold</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>Silver</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic    class  count\n",
       "0       0     Gold      4\n",
       "1       0  Diamond      1\n",
       "2       0   Silver      1\n",
       "3       1  Diamond      9\n",
       "4       1   Silver      8\n",
       "5       1     Gold      7\n",
       "6       2  Diamond      5\n",
       "7       2     Gold      2\n",
       "8       2   Silver      1\n",
       "9       3   Silver      4\n",
       "10      4     Gold      2\n",
       "11      4   Silver      1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the distribution of classes within each cluster\n",
    "cluster_class_distribution = video_transcripts.groupby('topic')['class'].value_counts()\n",
    "\n",
    "# Convert to DataFrame for better readability\n",
    "cluster_class_distribution_df = cluster_class_distribution.reset_index(name='count')\n",
    "cluster_class_distribution_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d25739a-ddbb-47e8-9460-d5ee70799f7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
